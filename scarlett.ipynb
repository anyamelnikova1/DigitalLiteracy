{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что я сделала для цг \n",
    "### Код не запускать!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. с помощью гугл формс у нас сформировалась табличка с данными \n",
    "2. я скопировала данные из таблички, привязанной к гугл формс в другую табличку, переименовав столбцы чтобы названия были уникальными и короткими\n",
    "3. скачала в формате TSV\n",
    "\t1. почему не csv? потому что у нас много кто писал ассоциации через запятую и если бы мы сохранили в формате csv то столбцы бы поплыли. \n",
    "\t2. Но я тут вообщето собираюсь работать с **pandas**, а pandas работает только с csv файлами. Что же делать?\n",
    "4. Открываем наш tsv файл в ББЭдит и сейчас будем делать **регулярные выражения**. Находим какой-нибудь знак препинания, которого нет ни в одном ответе\n",
    "\t1.  find , replace ~\n",
    "\t2. find \\t replace ,\t\n",
    "\t3. save as csv \n",
    "\t4. проверить в гугол таблицах что все работает нормально и  ничего не поехало\n",
    "\t5. Сохраняем файл в то же место где питон файлик, называем scarlet.csv\n",
    "\n",
    "## Питончик\n",
    "Импортирую библиотеки **pandas** **natasa**  **wordcloud** и делаю все как написано у наташи в гитхабе чтоб она заваьотала как надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk pandas natasha razdel wordcloud matplotlib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "scarlet = pd.read_csv(\"/Users/anyamelnikova/Desktop/vs/python/digitallit/scarlet.csv\")\n",
    "from razdel import tokenize\n",
    "from wordcloud import WordCloud\n",
    "import colorsys\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "from natasha import MorphVocab, Doc, NewsMorphTagger, NewsEmbedding, NamesExtractor, Segmenter\n",
    "# из гитхаба наташи копируем все что нужно для работы чтобы запускалась\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "morph_vocab = MorphVocab()\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "segmenter = Segmenter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция 1. Записываем ассоциации в файлики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepfunc(column, wordfile): \n",
    "    lst = []\n",
    "    for i in range(len(scarlet[column])):\n",
    "        lst.append(list(map(str, scarlet[column][i].split(\"~\"))))\n",
    "    f = open(wordfile, 'w')\n",
    "    for  i in range(len(lst)): \n",
    "        lst[i] += \" \"     \n",
    "        for j in range(len(lst[i])):\n",
    "            f.writelines(str(lst[i][j]))\n",
    "    f.close() \n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполняем функцию 1 и открвыаем все наше великолепие на почитать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepfunc(\"ideas1\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_1')\n",
    "sepfunc(\"ideas2\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_2')\n",
    "sepfunc(\"ideas3\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_3')\n",
    "sepfunc(\"ideas4\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_4')\n",
    "sepfunc(\"ideas5\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_5')\n",
    "sepfunc(\"ideas6\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_6')\n",
    "sepfunc(\"ideas7\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_7')\n",
    "sepfunc(\"ideas8\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_8')\n",
    "sepfunc(\"ideas9\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_9')\n",
    "\n",
    "wordfile1 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_1', 'r')\n",
    "wordfile2 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_2', 'r')\n",
    "wordfile3 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_3', 'r')\n",
    "wordfile4 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_4', 'r')\n",
    "wordfile5 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_5', 'r')\n",
    "wordfile6 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_6', 'r')\n",
    "wordfile7 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_7', 'r')\n",
    "wordfile8 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_8', 'r')\n",
    "wordfile9 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_9', 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция 2 выделаем все существительные и приланательные (с помощью наташи)\n",
    "\n",
    "#### ведь там как будто бы весь нужный нам смысл. Мы сначала разбиваем все на токены, потом\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['бабочка', 'выпускной', 'розовый', 'сумка', 'летний', 'женский', 'платье', 'тюльпан', 'роза', 'малиновый', 'искусственный', 'цвет', 'пластик', 'красный', 'итог', 'фигня', 'цветок', 'блеск', 'губа', '2014', 'год', 'розоватый', 'барби', 'розовый', 'жесткий', 'противный', 'мороженое', 'химозный', 'краситель', 'пинок', 'пай', 'кричащий', 'приятный', 'искусственный', 'губный', 'помада', 'русалочка', 'цветок', 'маникюр', 'барби', 'розовый', 'барби', 'романтика', 'вежливость', 'коралловый', 'розовый', 'спокойствие', 'умиротворение', 'патрик', 'губка', 'боб', 'розовый', 'милый', 'малиновый', 'кисель', 'яркость', 'новизна', 'цветок', 'леденец', 'платье', 'кукла', 'цвет', 'туфля', 'девочка', 'год', 'цвет', 'красный', 'малиновый', 'купальник', 'мода', 'блеск', 'губа', 'алый', 'яркий', 'этикетка', 'алый', 'светлый', 'выцветший', 'красный', 'год', 'коттедж', 'платье', 'середина', 'xx', 'век']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nounadj(wordfile):\n",
    "    lst = []\n",
    "    words = wordfile.readline()\n",
    "    tokens = list(tokenize(words))\n",
    "    doc = Doc(words)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lst.append(token.lemma) \n",
    "\n",
    "    for item in lst:\n",
    "        if item.isalnum() == False:\n",
    "            lst.remove(item)\n",
    "        else:\n",
    "            item.lower()            \n",
    "    return lst\n",
    "\n",
    "\n",
    "nounadj1 = nounadj(wordfile1)\n",
    "nounadj2 = nounadj(wordfile2)\n",
    "nounadj3 = nounadj(wordfile3)\n",
    "nounadj4 = nounadj(wordfile4)\n",
    "nounadj5 = nounadj(wordfile5)\n",
    "nounadj6 = nounadj(wordfile6)\n",
    "nounadj7 = nounadj(wordfile7)\n",
    "nounadj8 = nounadj(wordfile8)\n",
    "nounadj9 = nounadj(wordfile9)\n",
    "print(nounadj3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция 3. хочу облако слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x11e2f8ca0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "color = 'xkcd:blood red'            \n",
    "r,g,b = colors.to_rgb(color)       \n",
    "h,l,s = colorsys.rgb_to_hls(r,g,b)\n",
    "\n",
    "hsl_val = 'hsl(' + str(h*360) + ', 100%%, %d%%)'\n",
    "def hsl_color_func(word, font_size, position, orientation, random_state = None, **kwargs):\n",
    "    return(hsl_val % np.random.randint(15,70))\n",
    "\n",
    "\n",
    "def clouds(nounad):\n",
    "    # делаем из списка слов nounadj строку из слов\n",
    "    nounstr = \"\"\n",
    "    for i in range(len(nounad)):\n",
    "        nounstr += nounad[i]\n",
    "        nounstr+= \" \"\n",
    "    cloud = WordCloud(width = 2000, \n",
    "                        height = 1500, \n",
    "                        random_state=1,  \n",
    "                        background_color= 'pink',\n",
    "                        margin=20, \n",
    "                        collocations=False).generate(nounstr)\n",
    "    cloud.recolor(color_func = hsl_color_func)\n",
    "    return cloud\n",
    "\n",
    "\n",
    "clouds(nounadj1).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud1.png')\n",
    "clouds(nounadj2).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud2.png')\n",
    "clouds(nounadj3).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud3.png')\n",
    "clouds(nounadj4).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud4.png')\n",
    "clouds(nounadj5).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud5.png')\n",
    "clouds(nounadj6).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud6.png')\n",
    "clouds(nounadj7).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud7.png')\n",
    "clouds(nounadj8).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud8.png')\n",
    "clouds(nounadj9).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud9.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хочу для каждого цвета посчитать наиболее частые слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(nounad):\n",
    "    fdist = FreqDist(nounad)\n",
    "    a = fdist.most_common(100)\n",
    "    # b = fdist.plot(30,cumulative=False) потом понадобится, рисует график\n",
    "    return a\n",
    "\n",
    "freq1 = frequency(nounadj1)\n",
    "freq2 = frequency(nounadj2)\n",
    "freq3 = frequency(nounadj3)\n",
    "freq4 = frequency(nounadj4)\n",
    "freq5 = frequency(nounadj5)\n",
    "freq6 = frequency(nounadj6)\n",
    "freq7 = frequency(nounadj7)\n",
    "freq8 = frequency(nounadj8)\n",
    "freq9 = frequency(nounadj9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### мб у восприятия цаета есть какаято гендерная история??\n",
    " разделим по полам и посмотрим, есть ли разница\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('вино', 3), ('оттенок', 1), ('помада', 1), ('закат', 1), ('клубника', 1), ('спокойствие', 1), ('успех', 1), ('свобода', 1), ('цвет', 1), ('глаз', 1), ('карта', 1), ('игральные', 1)]\n"
     ]
    }
   ],
   "source": [
    "def discrimination(column, mf): # mf может быть либо мужской, либо женский\n",
    "    lst = []\n",
    "    for i in range(len(scarlet[column])):\n",
    "        if scarlet['gender'][i] == mf:\n",
    "            lst.append(list(map(str, scarlet[column][i].split(\"~\"))))\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'w')\n",
    "    for  i in range(len(lst)): \n",
    "        lst[i] += \" \"     \n",
    "        for j in range(len(lst[i])):\n",
    "            f.writelines(str(lst[i][j]))\n",
    "    f.close()      \n",
    "    lst = []\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'r')\n",
    "    male = f.readline()          \n",
    "    tokens = list(tokenize(male))\n",
    "    doc = Doc(male)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lst.append(token.lemma) \n",
    "\n",
    "    for item in lst:\n",
    "        if item.isalnum() == False:\n",
    "            lst.remove(item)\n",
    "        else:\n",
    "            item.lower()        \n",
    "    fdist = FreqDist(lst)\n",
    "    a = fdist.most_common(100)                  \n",
    "    return a \n",
    "\n",
    "\n",
    "\n",
    "male1 = discrimination('ideas1', \"Мужской\")\n",
    "male2 = discrimination('ideas2', \"Мужской\")\n",
    "male3 = discrimination('ideas3', \"Мужской\")\n",
    "male4 = discrimination('ideas4', \"Мужской\")\n",
    "male5 = discrimination('ideas5', \"Мужской\")\n",
    "male6 = discrimination('ideas6', \"Мужской\")\n",
    "male7 = discrimination('ideas7', \"Мужской\")\n",
    "male8 = discrimination('ideas8', \"Мужской\")\n",
    "male9 = discrimination('ideas9', \"Мужской\")\n",
    "\n",
    "female1 = discrimination('ideas1', \"Женский\")\n",
    "female2 = discrimination('ideas2', \"Женский\")\n",
    "female3 = discrimination('ideas3', \"Женский\")\n",
    "female4 = discrimination('ideas4', \"Женский\")\n",
    "female5 = discrimination('ideas5', \"Женский\")\n",
    "female6 = discrimination('ideas6', \"Женский\")\n",
    "female7 = discrimination('ideas7', \"Женский\")\n",
    "female8 = discrimination('ideas8', \"Женский\")\n",
    "female9 = discrimination('ideas9', \"Женский\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксель для подсчета какой красный самый красный \n",
    "_Берем столбцы grade и там делаем =сумм(всех) разлелить на количество_\n",
    "## Что еще надо? ВСЕ ЗАПРИНТИТЬ И ПОДУМАТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
