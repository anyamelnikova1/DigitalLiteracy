{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что я сделала для цг \n",
    "### Код не запускать!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. с помощью гугл формс у нас сформировалась табличка с данными \n",
    "2. я скопировала данные из таблички, привязанной к гугл формс в другую табличку, переименовав столбцы чтобы названия были уникальными и короткими\n",
    "3. скачала в формате TSV\n",
    "\t1. почему не csv? потому что у нас много кто писал ассоциации через запятую и если бы мы сохранили в формате csv то столбцы бы поплыли. \n",
    "\t2. Но я тут вообщето собираюсь работать с **pandas**, а pandas работает только с csv файлами. Что же делать?\n",
    "4. Открываем наш tsv файл в ББЭдит и сейчас будем делать **регулярные выражения**. Находим какой-нибудь знак препинания, которого нет ни в одном ответе\n",
    "\t1.  find , replace ~\n",
    "\t2. find \\t replace ,\t\n",
    "\t3. save as csv \n",
    "\t4. проверить в гугол таблицах что все работает нормально и  ничего не поехало\n",
    "\t5. Сохраняем файл в то же место где питон файлик, называем scarlet.csv\n",
    "\n",
    "## Питончик\n",
    "Импортирую библиотеки **pandas** **natasa**  **wordcloud** и делаю все как написано у наташи в гитхабе чтоб она заваьотала как надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk pandas natasha razdel wordcloud matplotlib \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!! Если хотите запустить код, не забудьте сментить пути до файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "scarlet = pd.read_csv(\"/Users/anyamelnikova/Desktop/vs/python/digitallit/scarlet.csv\")\n",
    "from razdel import tokenize\n",
    "from wordcloud import WordCloud\n",
    "import colorsys\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "from natasha import MorphVocab, Doc, NewsMorphTagger, NewsEmbedding, NamesExtractor, Segmenter\n",
    "# из гитхаба наташи копируем все что нужно для работы чтобы запускалась\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "morph_vocab = MorphVocab()\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "segmenter = Segmenter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция 1. Записываем ассоциации в файлики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepfunc(column, wordfile): \n",
    "    lst = []\n",
    "    for i in range(len(scarlet[column])):\n",
    "        lst.append(list(map(str, scarlet[column][i].split(\"~\"))))\n",
    "    f = open(wordfile, 'w')\n",
    "    for  i in range(len(lst)): \n",
    "        lst[i] += \" \"     \n",
    "        for j in range(len(lst[i])):\n",
    "            f.writelines(str(lst[i][j]))\n",
    "    f.close() \n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполняем функцию 1 и открвыаем все наше великолепие на почитать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepfunc(\"ideas1\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_1')\n",
    "sepfunc(\"ideas2\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_2')\n",
    "sepfunc(\"ideas3\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_3')\n",
    "sepfunc(\"ideas4\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_4')\n",
    "sepfunc(\"ideas5\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_5')\n",
    "sepfunc(\"ideas6\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_6')\n",
    "sepfunc(\"ideas7\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_7')\n",
    "sepfunc(\"ideas8\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_8')\n",
    "sepfunc(\"ideas9\", '/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_9')\n",
    "\n",
    "wordfile1 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_1', 'r')\n",
    "wordfile2 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_2', 'r')\n",
    "wordfile3 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_3', 'r')\n",
    "wordfile4 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_4', 'r')\n",
    "wordfile5 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_5', 'r')\n",
    "wordfile6 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_6', 'r')\n",
    "wordfile7 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_7', 'r')\n",
    "wordfile8 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_8', 'r')\n",
    "wordfile9 = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/ wordies_9', 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция 2 выделаем все существительные и приланательные (с помощью наташи)\n",
    "\n",
    "#### ведь там как будто бы весь нужный нам смысл. Мы сначала разбиваем все на токены, потом\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nounadj(wordfile):\n",
    "    lst = []\n",
    "    words = wordfile.readline()\n",
    "    tokens = list(tokenize(words))\n",
    "    doc = Doc(words)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lst.append(token.lemma) \n",
    "\n",
    "    for item in lst:\n",
    "        if item.isalpha() == False:\n",
    "            lst.remove(item)\n",
    "        else:\n",
    "            item.lower()\n",
    "    return lst\n",
    "\n",
    "\n",
    "nounadj1 = nounadj(wordfile1)\n",
    "nounadj2 = nounadj(wordfile2)\n",
    "nounadj3 = nounadj(wordfile3)\n",
    "nounadj4 = nounadj(wordfile4)\n",
    "nounadj5 = nounadj(wordfile5)\n",
    "nounadj6 = nounadj(wordfile6)\n",
    "nounadj7 = nounadj(wordfile7)\n",
    "nounadj8 = nounadj(wordfile8)\n",
    "nounadj9 = nounadj(wordfile9)\n",
    "print(nounadj1)\n",
    "print(nounadj2)\n",
    "print(nounadj3)\n",
    "print(nounadj4)\n",
    "print(nounadj5)\n",
    "print(nounadj6)\n",
    "print(nounadj7)\n",
    "print(nounadj8)\n",
    "print(nounadj9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция 3. хочу облако слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "color = 'xkcd:blood red'            \n",
    "r,g,b = colors.to_rgb(color)       \n",
    "h,l,s = colorsys.rgb_to_hls(r,g,b)\n",
    "\n",
    "hsl_val = 'hsl(' + str(h*360) + ', 100%%, %d%%)'\n",
    "def hsl_color_func(word, font_size, position, orientation, random_state = None, **kwargs):\n",
    "    return(hsl_val % np.random.randint(15,70))\n",
    "\n",
    "\n",
    "def clouds(nounad):\n",
    "    # делаем из списка слов nounadj строку из слов\n",
    "    nounstr = \"\"\n",
    "    for i in range(len(nounad)):\n",
    "        nounstr += nounad[i]\n",
    "        nounstr+= \" \"\n",
    "    cloud = WordCloud(width = 2000, \n",
    "                        height = 1500, \n",
    "                        random_state=1,  \n",
    "                        background_color= 'pink',\n",
    "                        margin=20, \n",
    "                        collocations=False).generate(nounstr)\n",
    "    cloud.recolor(color_func = hsl_color_func)\n",
    "    return cloud\n",
    "\n",
    "\n",
    "clouds(nounadj1).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud1.png')\n",
    "clouds(nounadj2).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud2.png')\n",
    "clouds(nounadj3).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud3.png')\n",
    "clouds(nounadj4).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud4.png')\n",
    "clouds(nounadj5).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud5.png')\n",
    "clouds(nounadj6).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud6.png')\n",
    "clouds(nounadj7).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud7.png')\n",
    "clouds(nounadj8).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud8.png')\n",
    "clouds(nounadj9).to_file('/Users/anyamelnikova/Desktop/vs/python/digitallit/cloud9.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хочу для каждого цвета посчитать наиболее частые слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(nounad):\n",
    "    fdist = FreqDist(nounad)\n",
    "    a = fdist.most_common(100)\n",
    "    b = fdist.plot(30,cumulative=False)\n",
    "    return a, b\n",
    "\n",
    "freq1 = frequency(nounadj1)\n",
    "freq2 = frequency(nounadj2)\n",
    "freq3 = frequency(nounadj3)\n",
    "freq4 = frequency(nounadj4)\n",
    "freq5 = frequency(nounadj5)\n",
    "freq6 = frequency(nounadj6)\n",
    "freq7 = frequency(nounadj7)\n",
    "freq8 = frequency(nounadj8)\n",
    "freq9 = frequency(nounadj9)\n",
    "\n",
    "print(freq1)\n",
    "print(freq2)\n",
    "print(freq3)\n",
    "print(freq4)\n",
    "print(freq5)\n",
    "print(freq6)\n",
    "print(freq7)\n",
    "print(freq8)\n",
    "print(freq9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# мб у восприятия цаета есть какаято гендерная история??\n",
    " разделим по полам и посмотрим, есть ли разница\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrimination(column, mf): # mf может быть либо мужской, либо женский\n",
    "    lst = []\n",
    "    for i in range(len(scarlet[column])):\n",
    "        if scarlet['gender'][i] == mf:\n",
    "            lst.append(list(map(str, scarlet[column][i].split(\"~\"))))\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'w')\n",
    "    for  i in range(len(lst)): \n",
    "        lst[i] += \" \"     \n",
    "        for j in range(len(lst[i])):\n",
    "            f.writelines(str(lst[i][j]))\n",
    "    f.close()      \n",
    "    lst = []\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'r')\n",
    "    male = f.readline()          \n",
    "    tokens = list(tokenize(male))\n",
    "    doc = Doc(male)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lst.append(token.lemma) \n",
    "\n",
    "    for item in lst:\n",
    "        if item.isalnum() == False:\n",
    "            lst.remove(item)\n",
    "        else:\n",
    "            item.lower()        \n",
    "    fdist = FreqDist(lst)\n",
    "    a = fdist.most_common(100)                  \n",
    "    return a \n",
    "\n",
    "\n",
    "\n",
    "male1 = discrimination('ideas1', \"Мужской\")\n",
    "male2 = discrimination('ideas2', \"Мужской\")\n",
    "male3 = discrimination('ideas3', \"Мужской\")\n",
    "male4 = discrimination('ideas4', \"Мужской\")\n",
    "male5 = discrimination('ideas5', \"Мужской\")\n",
    "male6 = discrimination('ideas6', \"Мужской\")\n",
    "male7 = discrimination('ideas7', \"Мужской\")\n",
    "male8 = discrimination('ideas8', \"Мужской\")\n",
    "male9 = discrimination('ideas9', \"Мужской\")\n",
    "print(male1)\n",
    "print(male2)\n",
    "print(male3)\n",
    "print(male4)\n",
    "print(male5)\n",
    "print(male6)\n",
    "print(male7)\n",
    "print(male8)\n",
    "print(male9)\n",
    "print(\"\\n\\n\\n\")\n",
    "female1 = discrimination('ideas1', \"Женский\")\n",
    "female2 = discrimination('ideas2', \"Женский\")\n",
    "female3 = discrimination('ideas3', \"Женский\")\n",
    "female4 = discrimination('ideas4', \"Женский\")\n",
    "female5 = discrimination('ideas5', \"Женский\")\n",
    "female6 = discrimination('ideas6', \"Женский\")\n",
    "female7 = discrimination('ideas7', \"Женский\")\n",
    "female8 = discrimination('ideas8', \"Женский\")\n",
    "female9 = discrimination('ideas9', \"Женский\")\n",
    "\n",
    "print(female1)\n",
    "print(female2)\n",
    "print(female3)\n",
    "print(female4)\n",
    "print(female5)\n",
    "print(female6)\n",
    "print(female7)\n",
    "print(female8)\n",
    "print(female9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксель для подсчета какой красный самый красный \n",
    "_Берем столбцы grade и там делаем =сумм(всех) разлелить на количество_\n",
    "\n",
    "## Возрастные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_young(column):\n",
    "    lst = []\n",
    "    for i in range(len(scarlet[column])):\n",
    "        if scarlet['age'][i] >= 30:\n",
    "            lst.append(list(map(str, scarlet[column][i].split(\"~\"))))\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'w')\n",
    "    for  i in range(len(lst)): \n",
    "        lst[i] += \" \"     \n",
    "        for j in range(len(lst[i])):\n",
    "            f.writelines(str(lst[i][j]))\n",
    "    f.close()      \n",
    "    lst = []\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'r')\n",
    "    male = f.readline()          \n",
    "    tokens = list(tokenize(male))\n",
    "    doc = Doc(male)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lst.append(token.lemma) \n",
    "\n",
    "    for item in lst:\n",
    "        if item.isalnum() == False:\n",
    "            lst.remove(item)\n",
    "        else:\n",
    "            item.lower()        \n",
    "    fdist = FreqDist(lst)\n",
    "    a = fdist.most_common(100)                  \n",
    "    return a \n",
    "\n",
    "def age_old(column):\n",
    "    lst = []\n",
    "    for i in range(len(scarlet[column])):\n",
    "        if scarlet['age'][i] < 30:\n",
    "            lst.append(list(map(str, scarlet[column][i].split(\"~\"))))\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'w')\n",
    "    for  i in range(len(lst)): \n",
    "        lst[i] += \" \"     \n",
    "        for j in range(len(lst[i])):\n",
    "            f.writelines(str(lst[i][j]))\n",
    "    f.close()      \n",
    "    lst = []\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/output', 'r')\n",
    "    male = f.readline()          \n",
    "    tokens = list(tokenize(male))\n",
    "    doc = Doc(male)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lst.append(token.lemma) \n",
    "\n",
    "    for item in lst:\n",
    "        if item.isalnum() == False:\n",
    "            lst.remove(item)\n",
    "        else:\n",
    "            item.lower()        \n",
    "    fdist = FreqDist(lst)\n",
    "    a = fdist.most_common(100)                  \n",
    "    return a \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эмоции в general\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = ['злость', 'агрессия', 'агрессивный', 'гнев', 'ярость', 'война']\n",
    "anxiety = ['опасность', 'нервный', 'тревога']\n",
    "pain = [\"кровь\", 'боль', 'смерть', 'умирать',]\n",
    "love = ['любовь', \"страсть\", \"секс\", \"сексуальность\"]\n",
    "communism = ['коммунизм', \"китай\", \"ссср\"]\n",
    "\n",
    "def general_emotions(lst):\n",
    "    ans = []\n",
    "    answers = []\n",
    "    for i in range(1, len(scarlet['general'])):\n",
    "        ans.append(scarlet['general'][i])\n",
    "    for i in range(len(ans)):\n",
    "        reply = []\n",
    "        tokens = list(tokenize(ans[i]))\n",
    "        doc = Doc(ans[i])\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        for token in doc.tokens:\n",
    "            if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "                token.lemmatize(morph_vocab)\n",
    "                reply.append(token.lemma) \n",
    "        for item in reply:\n",
    "            if item.isalpha() == False:\n",
    "                reply.remove(item)\n",
    "            else:\n",
    "                item.lower()\n",
    "        answers.append(reply) \n",
    "    count = 0\n",
    "    for i in range(len(answers)):\n",
    "        for j in range(len(lst)):\n",
    "            if lst[j] in answers[i]: \n",
    "                count +=1\n",
    "                break\n",
    "\n",
    "\n",
    "    return count          \n",
    "\n",
    "print(general_emotions(anger))\n",
    "print(general_emotions(anxiety))\n",
    "print(general_emotions(communism))\n",
    "print(general_emotions(pain)) \n",
    "print(general_emotions(love))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сколько людей связывают красный с опроеделеннвми понятиями и эмоциями\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = ['злость', 'агрессия', 'агрессивный', 'гнев', 'ярость', 'война']\n",
    "anxiety = ['опасность', 'нервный', 'тревога']\n",
    "pain = [\"кровь\", 'боль', 'смерть', 'умирать',]\n",
    "love = ['любовь', \"страсть\", \"секс\", \"сексуальность\"]\n",
    "communism = ['коммунизм', \"китай\", \"ссср\"]\n",
    "good_f = ['спокойный', 'спокойствие', 'уют', 'хороший', 'достоинство']\n",
    "\n",
    "def the_emotions(col, lst):\n",
    "    ans = []\n",
    "    answers = []\n",
    "    for i in range(1, len(scarlet[col])):\n",
    "        ans.append(scarlet[col][i])\n",
    "    for i in range(len(ans)):\n",
    "        reply = []\n",
    "        tokens = list(tokenize(ans[i]))\n",
    "        doc = Doc(ans[i])\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        for token in doc.tokens:\n",
    "            if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "                token.lemmatize(morph_vocab)\n",
    "                reply.append(token.lemma) \n",
    "        for item in reply:\n",
    "            if item.isalpha() == False:\n",
    "                reply.remove(item)\n",
    "            else:\n",
    "                item.lower()\n",
    "        answers.append(reply) \n",
    "    count = 0\n",
    "    for i in range(len(answers)):\n",
    "        for j in range(len(lst)):\n",
    "            if lst[j] in answers[i]: \n",
    "                count +=1\n",
    "            break\n",
    "    return count  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(the_emotions('ideas1', anger))\n",
    "print(the_emotions('ideas1', anxiety))\n",
    "print(the_emotions('ideas1', communism))\n",
    "print(the_emotions('ideas1', pain)) \n",
    "print(the_emotions('ideas1', love))\n",
    "print(the_emotions('ideas1', love))\n",
    "print(the_emotions('ideas1', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(the_emotions('ideas2', anger))\n",
    "print(the_emotions('ideas2', anxiety))\n",
    "print(the_emotions('ideas2', communism))\n",
    "print(the_emotions('ideas2', pain)) \n",
    "print(the_emotions('ideas2', love))\n",
    "print(the_emotions('ideas2', love))\n",
    "print(the_emotions('ideas2', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(the_emotions('ideas3', anger)end)\n",
    "print(the_emotions('ideas3', anxiety))\n",
    "print(the_emotions('ideas3', communism))\n",
    "print(the_emotions('ideas3', pain)) \n",
    "print(the_emotions('ideas3', love))\n",
    "print(the_emotions('ideas3', love))\n",
    "print(the_emotions('ideas3', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(the_emotions('ideas4', anger))\n",
    "print(the_emotions('ideas4', anxiety))\n",
    "print(the_emotions('ideas4', communism))\n",
    "print(the_emotions('ideas4', pain)) \n",
    "print(the_emotions('ideas4', love))\n",
    "print(the_emotions('ideas4', love))\n",
    "print(the_emotions('ideas4', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(the_emotions('ideas5', anger))\n",
    "print(the_emotions('ideas5', anxiety))\n",
    "print(the_emotions('ideas5', communism))\n",
    "print(the_emotions('ideas5', pain)) \n",
    "print(the_emotions('ideas5', love))\n",
    "print(the_emotions('ideas5', love))\n",
    "print(the_emotions('ideas5', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(the_emotions('ideas6', anger))\n",
    "print(the_emotions('ideas6', anxiety))\n",
    "print(the_emotions('ideas6', communism))\n",
    "print(the_emotions('ideas6', pain)) \n",
    "print(the_emotions('ideas6', love))\n",
    "print(the_emotions('ideas6', love))\n",
    "print(the_emotions('ideas6', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(the_emotions('ideas7', anger))\n",
    "print(the_emotions('ideas7', anxiety))\n",
    "print(the_emotions('ideas7', communism))\n",
    "print(the_emotions('ideas7', pain)) \n",
    "print(the_emotions('ideas7', love))\n",
    "print(the_emotions('ideas7', love))\n",
    "print(the_emotions('ideas7', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(the_emotions('ideas8', anger))\n",
    "print(the_emotions('ideas8', anxiety))\n",
    "print(the_emotions('ideas8', communism))\n",
    "print(the_emotions('ideas8', pain)) \n",
    "print(the_emotions('ideas8', love))\n",
    "print(the_emotions('ideas8', love))\n",
    "print(the_emotions('ideas8', good_f))\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(the_emotions('ideas9', anger))\n",
    "print(the_emotions('ideas9', anxiety))\n",
    "print(the_emotions('ideas9', communism))\n",
    "print(the_emotions('ideas9', pain)) \n",
    "print(the_emotions('ideas9', love))\n",
    "print(the_emotions('ideas9', love))\n",
    "print(the_emotions('ideas9', good_f))\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сколько человек какой цвет оценивают на 4 и 5 п прототипичности?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_red(col):\n",
    "    count = 0\n",
    "    for i in range(len(scarlet[col])):\n",
    "        if scarlet[col][i] >= 4:\n",
    "            count += 1\n",
    "    return count\n",
    "print(true_red('grade1'))\n",
    "print(true_red('grade2'))\n",
    "print(true_red('grade3'))\n",
    "print(true_red('grade4'))\n",
    "print(true_red('grade5'))\n",
    "print(true_red('grade6'))\n",
    "print(true_red('grade7'))\n",
    "print(true_red('grade8'))\n",
    "print(true_red('grade9'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эмоции по полам (провалено)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = ['злость', 'агрессия', 'агрессивный', 'гнев', 'ярость', 'война']\n",
    "anxiety = ['опасность', 'нервный', 'тревога']\n",
    "pain = [\"кровь\", 'боль', 'смерть', 'умирать',]\n",
    "love = ['любовь', \"страсть\", \"секс\", \"сексуальность\"]\n",
    "communism = ['коммунизм', \"китай\", \"ссср\"]\n",
    "good_f = ['спокойный', 'спокойствие', 'уют', 'хороший', 'достоинство']\n",
    "\n",
    "\n",
    "ideas = ['ideas1', 'ideas2', 'ideas3', 'ideas4', 'ideas5', 'ideas6', 'ideas7', 'ideas8', 'ideas9',]\n",
    "\n",
    "genders = ['Мужской', \"Женский\"]\n",
    "\n",
    "def mf_emotions(col, lst, mf):\n",
    "    ans = []\n",
    "    answers = []\n",
    "    for i in range(1, len(scarlet[col])):\n",
    "      if scarlet['gender'][i] == mf:\n",
    "        ans.append(scarlet[col][i])\n",
    "    for i in range(len(ans)):\n",
    "        reply = []\n",
    "        tokens = list(tokenize(ans[i]))\n",
    "        doc = Doc(ans[i])\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        for token in doc.tokens:\n",
    "            if token.pos == \"NOUN\" or token.pos == 'ADJ':\n",
    "                token.lemmatize(morph_vocab)\n",
    "                reply.append(token.lemma)\n",
    "        for item in reply:\n",
    "            if item.isalpha() == False:\n",
    "                reply.remove(item)\n",
    "            else:\n",
    "                item.lower()\n",
    "        answers.append(reply)\n",
    "    count = 0\n",
    "    for i in range(len(answers)):\n",
    "        for j in range(len(lst)):\n",
    "            if lst[j] in answers[i]:\n",
    "                count +=1\n",
    "            break\n",
    "    return count\n",
    "\n",
    "\n",
    "def writing():\n",
    "    f = open('/Users/anyamelnikova/Desktop/vs/python/digitallit/EMOTOINS','w')\n",
    "    for i in range(len(ideas)):\n",
    "      lst_male = [ mf_emotions(ideas[i],anger, 'Мужской'), mf_emotions(ideas[i],anxiety, 'Мужской'),mf_emotions(ideas[i],pain, 'Мужской'), mf_emotions(ideas[i],love, 'Мужской'), mf_emotions(ideas[i],anger, 'Мужской'), mf_emotions(ideas[i],anger, 'Мужской')]\n",
    "      lst_female =[mf_emotions(ideas[i],anger, 'Женский'), mf_emotions(ideas[i],anxiety, 'Женский'),mf_emotions(ideas[i],pain, 'Женский'), mf_emotions(ideas[i],love, 'Женский'), mf_emotions(ideas[i],anger, 'Женский'), mf_emotions(ideas[i],anger, 'Женский')]\n",
    "      f.write(str(i+1))\n",
    "      f.writelines(\"\\n\")\n",
    "      f.writelines('Мужской')\n",
    "      f.write(str(lst_male))\n",
    "      f.write('\\n')\n",
    "      f.write('Женский')\n",
    "      f.write(str(lst_female))\n",
    "      f.write('\\n\\n\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
